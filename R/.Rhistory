col = "red", bg = "yellow",
xlim = c(-10, 10), ylim =  c(-10, 10),
main = "Simulation of 2D Brownian Motion")}
a = saveGIF({
par(mar = rep(3, 4))
n = 10
tmax = 30
set.seed(20161013)
x = rnorm(n)
y = rnorm(n)
ani.options(interval = 0.5, nmax = tmax)
for (i in 1:tmax) {
plot(x, y, pch = 21, cex = 4,
col = "red", bg = "yellow",
xlim = c(-10, 10), ylim =  c(-10, 10),
main = "Simulation of 2D Brownian Motion")
text(x, y)
x = x + rnorm(n)
y = y + rnorm(n)
}
}, movie.name = "Brownian2.gif")
a = saveGIF({
par(mar = rep(3, 4))
n = 10
tmax = 30
set.seed(20161013)
x = rnorm(n)
y = rnorm(n)
ani.options(interval = 0.5, nmax = tmax)
for (i in 1:tmax) {
plot(x, y, pch = 21, cex = 4,
col = "red", bg = "yellow",
xlim = c(-10, 10), ylim =  c(-10, 10),
main = "Simulation of 2D Brownian Motion")
text(x, y)
x = x + rnorm(n)
y = y + rnorm(n)
}
}, movie.name = "Brownian2.gif")
ani.options(interval = 0.05, nmax = 150)
a = saveGIF({
par(mar = rep(3, 4))
n = 10
tmax = 30
set.seed(20161013)
x = rnorm(n)
y = rnorm(n)
ani.options(interval = 0.5, nmax = tmax)
for (i in 1:tmax) {
plot(x, y, pch = 21, cex = 4,
col = "red", bg = "yellow",
xlim = c(-10, 10), ylim =  c(-10, 10),
main = "Simulation of 2D Brownian Motion")
text(x, y)
x = x + rnorm(n)
y = y + rnorm(n)
}
}, movie.name = "Brownian2.gif")
ani.options(interval = 0.05, nmax = 150)
brownian.motion(pch = 21, cex = 5, col = "red", bg = "yellow",
main = "Demonstration of Brownian Motion")
library(readr)
library(tidyverse)
bands <- read_delim("../data/bands.csv", ";",
escape_double = FALSE, trim_ws = TRUE)
str(bands)
bands[c(2:20,40)] <- lapply(bands[c(2:20,40)], factor)
bands[c(21:39)] <- lapply(bands[c(21:39)], as.numeric)
bands$band_type_01<-ifelse(bands$band_type == 'band', 1,0)
str(bands)
head(bands)
library(DT)
library(tidyverse)
library(ggthemes)
library(RColorBrewer)
library(corrplot)
library(psych)
library(GGally)
library(corrr)
library(corrplot)
library(ggcorrplot)
library(kableExtra)
library(DataExplorer)
library(inspectdf)
summary(bands)
describe(bands)
bands_num <- bands[c(1,21:39)]
bands_num_nona <- bands_num %>% na.omit()
bands_cat <- bands[c(2:20, 40)]
introduce(bands)
plot_intro(bands[,-40])
plot_missing(bands)
plot_histogram(bands_num)
plot_density(bands_num,
ggtheme = theme_bw(), ncol = 4, nrow = 2)
plot_boxplot(bands[,-c(1:20)], by= 'band_type',  ncol = 2,
title = "Side-by-side boxplots", ggtheme = theme_bw()) +
scale_y_discrete(labels = c('Band', 'No band'))
#SANS NAs
corrplot(cor(bands_num_nona))
corrplot.mixed(cor(bands_num_nona), order="hclust", tl.col="black", tl.pos = "lt")
library(readr)
library(tidyverse)
bands <- read_delim("../data/bands.csv", ";",
escape_double = FALSE, trim_ws = TRUE)
str(bands)
bands[c(2:20,40)] <- lapply(bands[c(2:20,40)], factor)
bands[c(21:39)] <- lapply(bands[c(21:39)], as.numeric)
bands$band_type_01<-ifelse(bands$band_type == 'band', 1,0)
str(bands)
head(bands)
library(DT)
library(tidyverse)
library(ggthemes)
library(RColorBrewer)
library(corrplot)
library(psych)
library(GGally)
library(corrr)
library(corrplot)
library(ggcorrplot)
library(kableExtra)
library(DataExplorer)
library(inspectdf)
summary(bands)
describe(bands)
bands_num <- bands[c(1,21:39)]
bands_num_nona <- bands_num %>% na.omit()
bands_cat <- bands[c(2:20, 40)]
introduce(bands)
plot_intro(bands[,-40])
plot_missing(bands)
plot_histogram(bands_num)
plot_density(bands_num,
ggtheme = theme_bw(), ncol = 4, nrow = 2)
plot_boxplot(bands[,-c(1:20)], by= 'band_type',  ncol = 2,
title = "Side-by-side boxplots", ggtheme = theme_bw()) +
scale_y_discrete(labels = c('Band', 'No band'))
#SANS NAs
corrplot(cor(bands_num_nona))
corrplot.mixed(cor(bands_num_nona), order="hclust", tl.col="black", tl.pos = "lt")
library(rmdformats)
library(rworldmap)
library(rworldxtra)
library(ggmap)
library(tidyverse)
library(magrittr)
library(ptdspkg)
library(mapproj)
library(plotly)
library(tidytext)
library(readxl)
library(tibble)
library(ggplot2)
library(dplyr)
library(plot3D)
library(animation)
library(knitr)
library(kableExtra)
library(ggrepel)
library(future)
i <- 1
df <- data.frame()
while (i<=1000)  {
if ((i%%5==0) & (i%%3==0)) {
df <- rbind(df,c("Fuzzbizz"))
} else if (i%%5==0){
df <- rbind(df,c("Bizz"))
} else if (i%%3==0) {
df <- rbind(df,c("Fuzz"))
} else {
df <- rbind(df,c(i))
}
i <- i+1
}
df %>%
kable(col.names="Number") %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed", font_size = 7), full_width=FALSE)
cities <- tibble(
name = c("zurich", "bern", "lausanne", "geneva", "basel"),
language = c("german", "german", "french", "french", "german"),
latitude = c(47.369019, 46.948002, 46.519630, 46.204391, 47.559608),
longitude = c(8.538030, 7.448130, 6.632130, 6.143158, 7.580610)
)
cities <- cities %>%
mutate(volume = sapply(name, get_volume))
library(readr)
library(tidyverse)
library(naniar)
library(stringr)
bands <- read_delim("../data/bands.csv", ";",
escape_double = FALSE, trim_ws = TRUE)
bands <- bands %>% mutate_all(tolower) %>%
replace_with_na_all(condition = ~.x %in% common_na_strings) %>%
mutate_if(is.character, list(~na_if(., "?")))
bands[c(2:20,40)] <- lapply(bands[c(2:20,40)], factor)
bands[c(21:39)] <- lapply(bands[c(21:39)], as.numeric)
bands$band_type_01<-ifelse(bands$band_type == 'band', 1,0)
str(bands)
head(bands)
library(DT)
library(tidyverse)
library(ggthemes)
library(RColorBrewer)
library(corrplot)
library(psych)
library(GGally)
library(corrr)
library(corrplot)
library(ggcorrplot)
library(kableExtra)
library(DataExplorer)
library(inspectdf)
library(dplyr)
summary(bands)
describe(bands)
bands_num <- bands[c(1,21:39)]
bands_num_nona <- bands_num %>% na.omit()
bands_cat <- bands[c(2:20, 40)]
introduce(bands)
plot_intro(bands[,-40])
plot_missing(bands)
plot_histogram(bands_num)
plot_density(bands_num,
ggtheme = theme_bw(), ncol = 4, nrow = 2)
plot_boxplot(bands[,-c(1:20)], by= 'band_type',  ncol = 2,
title = "Side-by-side boxplots", ggtheme = theme_bw()) +
scale_y_discrete(labels = c('Band', 'No band'))
#SANS NAs
corrplot(cor(bands_num_nona)) #works if column 1 is numeric
mydictionnary<-nrc_emotions
library(sentimentr)
mydictionnary<-nrc_emotions
library(lexicon)
mydictionnary<-nrc_emotions
View(mydictionnary)
mydictionnary<-rbind(mydictionnary,comfort)
comfort<-rep(0, 14182)%>%t()
library(magrittr)
comfort<-rep(0, 14182)%>%t()
discomfort<-rep(0,14182)%>%t()
mydictionnary<-rbind(mydictionnary,comfort)
mydictionnary<-cbind(mydictionnary,comfort)
mydictionnary<-cbind(mydictionnary,discomfort)
View(mydictionnary)
View(comfort)
mydictionnary<-nrc_emotions
#anger,anticipation,disgust,fear,joy,sadness,surprise, trust,uncomfortable
mydictionnary
tight<-c("tight",0,0,1,0,0,1,0,0)
comfort<-rep(0, 14182)
discomfort<-rep(0,14182)
mydictionnary<-rbind(mydictionnary,comfort)
mydictionnary<-rbind(mydictionnary,discomfort)
View(mydictionnary)
mydictionnary<-nrc_emotions
#anger,anticipation,disgust,fear,joy,sadness,surprise, trust,uncomfortable
mydictionnary
comfort<-rep(0, 14182)
discomfort<-rep(0,14182)
mydictionnary<-cbind(mydictionnary,comfort)
mydictionnary<-cbind(mydictionnary,discomfort)
library(readxl)
sunscreen_dic <- read_excel("Documents/GitHub/textmining/data/sunscreen_dic.xlsx")
View(sunscreen_dic)
dictionnary<-rbind(mydictionnary, sunscreen_dic)
sunscreen_dic <- read_excel("Documents/GitHub/textmining/data/sunscreen_dic.xlsx")
dictionnary<-rbind(mydictionnary, sunscreen_dic)
colnames(sunscreen_dic)
colnames(mydictionnary)
sunscreen_dic <- read_excel("Documents/GitHub/textmining/data/sunscreen_dic.xlsx")
dictionnary<-rbind(mydictionnary, sunscreen_dic)
View(dictionnary)
#order by alphabetical order
dictionnary<-dictionnary[order(dictionnary$term),]
do.call(rbind,lapply(split(dictionnary,dictionnary$term),function(x) x[which.max(abs(dictionnary$comfort))||which.max(abs(dictionnary$discomfort)),]))
dictionnary<-do.call(rbind,lapply(split(dictionnary,dictionnary$term),function(x) x[which.max(abs(dictionnary$comfort))||which.max(abs(dictionnary$discomfort)),]))
View(dictionnary)
mydictionnary<-nrc_emotions
#anger,anticipation,disgust,fear,joy,sadness,surprise, trust,uncomfortable
mydictionnary
comfort<-rep(0, 14182)
discomfort<-rep(0,14182)
mydictionnary<-cbind(mydictionnary,comfort)
mydictionnary<-cbind(mydictionnary,discomfort)
sunscreen_dic <- read_excel("Documents/GitHub/textmining/data/sunscreen_dic.xlsx")
dictionnary<-rbind(mydictionnary, sunscreen_dic)
#order by alphabetical order
dictionnary<-dictionnary[order(dictionnary$term),]
mydictionnary<-nrc_emotions
#anger,anticipation,disgust,fear,joy,sadness,surprise, trust,uncomfortable
mydictionnary
comfort<-rep(0, 14182)
discomfort<-rep(0,14182)
mydictionnary<-cbind(mydictionnary,comfort)
mydictionnary<-cbind(mydictionnary,discomfort)
sunscreen_dic <- read_excel("Documents/GitHub/textmining/data/sunscreen_dic.xlsx")
dictionnary<-rbind(sunscreen_dic, mydictionnary)
View(dictionnary)
#order by alphabetical order
dictionnary<-dictionnary[order(dictionnary$term),]
dictionnary<-distinct(dictionnary$term)
dictionnary<-dplyr::distinct(dictionnary$term)
dictionnary %>% distinct(term, .keep_all = TRUE)
dictionnary %>% dplyr::distinct(term, .keep_all = TRUE)
dictionnary<-dictionnary %>% dplyr::distinct(term, .keep_all = TRUE)
library("projectg1ptds")
library(tidytext)
library(magrittr)
library(dplyr)
library(wordcloud)
library(ggplot2)
plot_sentimentsReddit <- function( word, stopwords) {
# install_cran("RedditExtractoR",force=T)
library("RedditExtractoR")
if(is.character(word)) {
data<-projectg1ptds::reddit_urls_mod(search_terms = "word", regex_filter = "", subreddit = "",
cn_threshold = 1, page_threshold = 1, sort_by = "new", time_frame= "week",
wait_time = 5)
stopwords_vec <- c(stopwords::stopwords("en"), "don", "isn", "gt", "i", word)
data.1 <- projectg1ptds::reddit_content(data[1:10,5], wait_time = 2)
data.1["comment"] <- tibble::as_tibble(sapply(contenu["comment"],
projectg1ptds::cleaning_text_function,
stopwords= c(stopwords::stopwords("en"), word, stopwords_vec )))
contenu_wordcloud <- data.1 %>%
mutate(comment2 = comment) %>%
tibble::as_tibble() %>%
unnest_tokens(word, comment) %>%
filter(is.na(as.numeric(word)))
contenu_wordcloud %>%
count(word) %>%
with(wordcloud(word, n, max.words = 50, colors=brewer.pal(8, "Spectral")))
##SentimentAnalysis:
contenu_sentiments <- contenu_wordcloud %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
group_by( sentiment) %>%
count()
ggplot(contenu_sentiments, aes(x = sentiment,y=n, fill = sentiment)) +
geom_bar(stat = "identity") +
theme_bw()+
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
labs(x = "", y = "Number of words", fill = "Sentiment")
}
plot_sentimentsReddit("Federer",stopwords_vec)
library("projectg1ptds")
library(tidytext)
library(magrittr)
library(dplyr)
library(wordcloud)
library(ggplot2)
plot_sentimentsReddit <- function( word, stopwords) {
# install_cran("RedditExtractoR",force=T)
library("RedditExtractoR")
if(is.character(word)) {
data<-projectg1ptds::reddit_urls_mod(search_terms = "word", regex_filter = "", subreddit = "",
cn_threshold = 1, page_threshold = 1, sort_by = "new", time_frame= "week",
wait_time = 5)
stopwords_vec <- c(stopwords::stopwords("en"), "don", "isn", "gt", "i", word)
data.1 <- projectg1ptds::reddit_content(data[1:10,5], wait_time = 2)
data.1["comment"] <- tibble::as_tibble(sapply(contenu["comment"],
projectg1ptds::cleaning_text_function,
stopwords= c(stopwords::stopwords("en"), word, stopwords_vec )))
contenu_wordcloud <- data.1 %>%
mutate(comment2 = comment) %>%
tibble::as_tibble() %>%
unnest_tokens(word, comment) %>%
filter(is.na(as.numeric(word)))
contenu_wordcloud %>%
count(word) %>%
with(wordcloud(word, n, max.words = 50, colors=brewer.pal(8, "Spectral")))
##SentimentAnalysis:
contenu_sentiments <- contenu_wordcloud %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
group_by( sentiment) %>%
count()
ggplot(contenu_sentiments, aes(x = sentiment,y=n, fill = sentiment)) +
geom_bar(stat = "identity") +
theme_bw()+
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
labs(x = "", y = "Number of words", fill = "Sentiment")
}
plot_sentimentsReddit("Federer",stopwords_vec)
plot_sentimentsReddit("Nadal",stopwords_vec)
setwd("~/Documents/GitHub/projectg1ptds/R")
devtools::document()
warnings()
devtools::document()
setwd("~/Documents/GitHub/group1_project/report ")
#trying the package
remotes::install_github("https://github.com/rsefraou/projectg1ptds")
library("projectg1ptds")
#scrappe le contenu des liens de discussion.
stopwords_vec <- c(stopwords::stopwords("en"), "don", "isn", "gt", "i")
projectg1ptds::plot_wordcloudReddit("Thunberg",stopwords_vec)
projectg1ptds::plot_sentimentsReddit("Thunberg", stopwords_vec)
plot_wordcloudReddits<-function(word, stopwords){
library("RedditExtractoR")
if(is.character(word)) {
data<-projectg1ptds::reddit_urls_mod(search_terms = "word", regex_filter = "", subreddit =NA,
cn_threshold = 1, page_threshold = 5, sort_by = "new",
time_frame= "day",
wait_time = 12)
stopwords_vec <- c(stopwords::stopwords("en"), "don", "isn", "gt", "i", word)
data.1 <- projectg1ptds::reddit_content(data[1:10,5], wait_time = 2)
data.1["comment"] <- tibble::as_tibble(sapply(data.1["comment"],
projectg1ptds::cleaning_text_function,
stopwords= c(stopwords::stopwords("en"), word, stopwords_vec )))
contenu_wordcloud <- data.1 %>%
mutate(comment2 = comment) %>%
tibble::as_tibble() %>%
tidytext::unnest_tokens(word, comment) %>%
filter(is.na(as.numeric(word)))
contenu_wordcloud %>%
count(word) %>%
with(wordcloud(word, n, max.words = 50, colors=brewer.pal(8, "Spectral")))
}}
plot_wordcloudReddits("Thunberg",stopwords_vec)
warnings()
data<-projectg1ptds::reddit_urls_mod(search_terms = "Thunberg", regex_filter = "", subreddit =NA,
cn_threshold = 1, page_threshold = 5, sort_by = "new",
time_frame= "day",
wait_time = 12)
#trying the package
remotes::install_github("https://github.com/rsefraou/projectg1ptds")
library("projectg1ptds")
#scrappe le contenu des liens de discussion.
stopwords_vec <- c(stopwords::stopwords("en"), "don", "isn", "gt", "i")
projectg1ptds::plot_wordcloudReddit("Thunberg",stopwords_vec)
warnings()
projectg1ptds::plot_wordcloudReddit("Nadal",stopwords_vec)
data<-projectg1ptds::reddit_urls_mod(search_terms = "Nadal", regex_filter = "", subreddit =NA,
cn_threshold = 1, page_threshold = 5, sort_by = "new",
time_frame= "day",
wait_time = 12)
setwd("~/Documents/GitHub/projectg1ptds/R")
devtools::document()
warnings()
#trying the package
remotes::install_github("https://github.com/rsefraou/projectg1ptds")
c
library("projectg1ptds")
data<-projectg1ptds::reddit_urls_mod(search_terms = "Nadal", regex_filter = "", subreddit =NA,
cn_threshold = 1, page_threshold = 5, sort_by = "new",
time_frame= "day",
wait_time = 12)
View(data)
data.1 <- projectg1ptds::reddit_content(data[1:10,5], wait_time = 2)
View(data.1)
contenu_sentiments <- contenu_wordcloud %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
dplyr::group_by(sentiment) %>%
plyr::count()
contenu_wordcloud <- data.1 %>%
tibble::as_tibble() %>%
tidytext::unnest_tokens(word, comment) %>%
filter(is.na(as.numeric(word)))
contenu_sentiments <- contenu_wordcloud %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
dplyr::group_by(sentiment) %>%
plyr::count()
ggplot(contenu_sentiments, aes(x = sentiment,y=n, fill = sentiment)) +
geom_bar(stat = "identity") +
theme_bw()+
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
labs(x = "", y = "Number of words", fill = "Sentiment")
View(contenu_sentiments)
ggplot(contenu_sentiments, aes(x = sentiment,y=freq, fill = sentiment)) +
geom_bar(stat = "identity") +
theme_bw()+
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
labs(x = "", y = "Number of words", fill = "Sentiment")
setwd("~/Documents/GitHub/projectg1ptds/R")
devtools::document()
projectg1ptds::plot_wordcloudReddit("Nadal",stopwords_vec)
contenu_sentiments <- contenu_wordcloud %>%
inner_join(get_sentiments("nrc"), by = word) %>%
dplyr::group_by(sentiment) %>%
plyr::count()
contenu_sentiments <- contenu_wordcloud %>%
inner_join(get_sentiments("nrc"), by = word) %>%
dplyr::group_by(sentiment) %>%
plyr::count()
contenu_sentiments <- contenu_wordcloud %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
dplyr::group_by(sentiment) %>%
plyr::count()
contenu_sentiments <- contenu_wordcloud %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
dplyr::group_by(sentiment) %>%
dplyr::count()
View(contenu_sentiments)
devtools::document()
#trying the package
remotes::install_github("https://github.com/rsefraou/projectg1ptds")
library("projectg1ptds")
projectg1ptds::plot_wordcloudReddit("Nadal",stopwords_vec)
Q
projectg1ptds::plot_wordcloudReddit("Nadal",stopwords_vec)
library("projectg1ptds")
#scrappe le contenu des liens de discussion.
stopwords_vec <- c(stopwords::stopwords("en"), "don", "isn", "gt", "i")
projectg1ptds::plot_wordcloudReddit("Nadal",stopwords_vec)
projectg1ptds::plot_sentimentsReddit("Thunberg", stopwords_vec)
projectg1ptds::plot_sentimentsReddit("Greta Thunberg", stopwords_vec)
projectg1ptds::plot_sentimentsReddit("Rafael Nadal", stopwords_vec)
contenu_wordcloud <- data.1 %>%
mutate(comment2 = comment) %>%
tibble::as_tibble() %>%
tidytext::unnest_tokens(word, comment) %>%
filter(is.na(as.numeric(word)))
projectg1ptds::plot_sentimentsReddit("Federer", stopwords_vec)
library(lexicon)
