setwd("~/Documents/GitHub/projectg1ptds/R")
devtools::document()
#trying the package
remotes::install_github("github.com/rsefraou/projectg1ptds")
#trying the package
remotes::install_github("https://github.com/rsefraou/projectg1ptds")
library("projectg1ptds")
Adresses<-projectg1ptds::reddit_urls_mod(search_terms = "federer", regex_filter = "", subreddit = "tennis",
cn_threshold = 1, page_threshold = 25, sort_by = "new", time_frame= "all",
wait_time = 4)
install_cran("RedditExtractoR")
install_cran("RedditExtractoR",force=T)
setwd("~/Documents/GitHub/projectg1ptds/R")
devtools::document()
#trying the package
remotes::install_github("https://github.com/rsefraou/projectg1ptds")
library("projectg1ptds")
Adresses<-projectg1ptds::reddit_urls_mod(search_terms = "federer", regex_filter = "", subreddit = "tennis",
cn_threshold = 1, page_threshold = 25, sort_by = "new", time_frame= "all",
wait_time = 4)
devtools::document()
#trying the package
remotes::install_github("https://github.com/rsefraou/projectg1ptds")
library("projectg1ptds")
Adresses<-projectg1ptds::reddit_urls_mod(search_terms = "federer", regex_filter = "", subreddit = "tennis",
cn_threshold = 1, page_threshold = 25, sort_by = "new", time_frame= "all",
wait_time = 4)
remotes::install_cran("RedditExctractoR", force=T)
install_cran("RedditExtractoR",force=T)
install_cran("RedditExctractoR", force=T)
install_cran("RedditExtractoR",force=T)
devtools::document()
#trying the package
remotes::install_github("https://github.com/rsefraou/projectg1ptds")
library("projectg1ptds")
Adresses<-projectg1ptds::reddit_urls_mod(search_terms = "federer", regex_filter = "", subreddit = "tennis",
cn_threshold = 1, page_threshold = 25, sort_by = "new", time_frame= "all",
wait_time = 4)
View(Adresses)
#scrappe le contenu des liens de discussion.
contenu <- projectg1ptds::reddit_content(Adresses[1:10,5], wait_time = 2)
#scrappe le contenu des liens de discussion.
stopwords_vec <- c(stopwords("english"), "don", "isn", "gt", "i")
contenu <- projectg1ptds::reddit_content(Adresses[1:10,5], wait_time = 2)
devtools::document()
setwd("~/Documents/GitHub/projectg1ptds/R")
devtools::document()
install.packages("textmineR")
library(RedditExtractoR)
sessionInfo()
library(projectg1ptds)
devtools::document()
library(projectg1ptds)
devtools::document()
warnings()
devtools::document()
library(projectg1ptds)
projectg1ptds::reddit_urls_mod("Federer", stopwords::stopwords())
a<-projectg1ptds::reddit_urls_mod("Federer", stopwords::stopwords())
View(a)
a<-projectg1ptds::reddit_urls_mod("Federer", stopwords::stopwords(), wait_time = 12)
View(a)
projectg1ptds::plot_sentimentsReddit("Federer", stopwords::stopwords())
library(projectg1ptds)
a <- projectg1ptds::plot_sentimentsReddit("Federer", stopwords::stopwords())
library(projectg1ptds)
a <- projectg1ptds::plot_sentimentsReddit("Federer", stopwords::stopwords())
??stopwords_vec
stopwords_vec
stopwords::stopwords()
library(projectg1ptds)
projectg1ptds::plot_sentimentsReddit("Federer", stopwords::stopwords())
library(projectg1ptds)
devtools::document()
library(projectg1ptds)
projectg1ptds::plot_sentimentsReddit("Federer", stopwords::stopwords())
library(projectg1ptds)
projectg1ptds::plot_sentimentsReddit("Federer", stopwords::stopwords())
reddit_content("https://www.reddit.com/r/SkincareAddiction/")
View(a)
ay<-reddit_content("https://www.reddit.com/r/SkincareAddiction/")
View(ay)
devtools::document()
#trying the package
remotes::install_github("https://github.com/rsefraou/projectg1ptds")
library("projectg1ptds")
Nadal<-projectg1ptds::reddit_urls_mod(search_terms="Nadal", subreddit="", sort_by = "new", time_frame = "week")
Nadal<-projectg1ptds::reddit_urls_mod(search_terms="Nadal", subreddit=NA, sort_by = "new", time_frame = "week")
projectg1ptds::plot_wordcloud_reddit("Nadal", stopwords_vec)
Nadal<-projectg1ptds::reddit_urls_mod(search_terms="Nadal", subreddit=NA, sort_by = "new", time_frame = "week")
Nadal<-projectg1ptds::reddit_urls_mod(search_terms="Nadal", subreddit= NA, sort_by = "new", time_frame = "week")
load("/Users/rsefraou/Downloads/Telegram Desktop/rida.rda")
b1 <- b
b1$date<-ymd_hm(b1$date)
b2 <- separate(b1,date, into = c("date","time"), sep =" ")
library(tidytext)
library(magrittr)
library(dplyr)
library(wordcloud)
library(ggplot2)
library("projectg1ptds")
library("tibble")
library("tidyr")
library("ggplot2")
install.packages("projectg1ptds")
b2 <- separate(b1,date, into = c("date","time"), sep =" ")
b1<-b %>% dplyr::mutate(year = lubridate::year(date),
month = lubridate::month(date),
day = lubridate::day(date),
hour = lubridate::hour(date),
minute =lubridate :: minute(date))
b1$hour <-as.factor(b1$hour)
b2$ID <- seq.int(nrow(b2))
b1$ID <- seq.int(nrow(b1))
b2$time <- format(b2$time, format = "%H:%M:%S")
b3<-b1%>%
tibble::as_tibble() %>%
tidytext::unnest_tokens(word, comment) %>%
dplyr::filter(is.na(as.numeric(word)))
drv<- b3%>%
dplyr::select(hour , word,ID)%>%
dplyr::group_by(ID)%>%
dplyr::inner_join(tidytext::get_sentiments("afinn"), by = "word")
afinn <- b1 %>%
dplyr::inner_join(tidytext::get_sentiments("afinn"), by= c("word"="comment")) %>%
dplyr::group_by(index = linenumber %/% 80) %>%
dplyr::summarise(sentiment = sum(value)) %>%
dplyr::mutate(method = "AFINN")
drv2<- drv%>%
dplyr::group_by(ID, hour )%>%
dplyr::summarize(y=mean(value))
drv3<-drv%>%
dplyr::mutate(value2=as.factor(value))%>%
dplyr::group_by(hour,)%>%
dplyr::summarise(mean=mean(as.numeric(value2)))
ggplot(b1, aes(x=hour))+
geom_bar(aes(fill = as.numeric(drv$value)))+
ggtitle("Number of comments per hour of the day of a given user")
drv<- b3%>%
dplyr::select(hour , word,ID)%>%
dplyr::group_by(ID)%>%
dplyr::inner_join(tidytext::get_sentiments("afinn"), by = "word")
View(drv)
source('~/Documents/GitHub/group1_project/report /test_package.R')
install.packages("projectg1ptds")
afinn <- b1 %>%
dplyr::inner_join(tidytext::get_sentiments("afinn"), by= c("word"="comment")) %>%
dplyr::group_by(index = linenumber %/% 500) %>%
dplyr::summarise(sentiment = sum(value)) %>%
dplyr::mutate(method = "AFINN")
drv2<- drv%>%
dplyr::group_by(ID, hour )%>%
dplyr::summarize(y=mean(value))
drv2<- drv%>%
dplyr::group_by(ID, hour )%>%
dplyr::summarize(y=mean(value))
View(drv2)
drv3<-drv%>%
dplyr::mutate(value2=as.factor(value))%>%
dplyr::group_by(hour,)%>%
dplyr::summarise(mean=mean(as.numeric(value2)))%>%
dplyr::count()
View(drv3)
drv3<-drv%>%
dplyr::mutate(value2=as.factor(value))%>%
dplyr::group_by(hour,)%>%
dplyr::summarise(mean=mean(as.numeric(value2)))
View(drv3)
ggplot(b1, aes(x=hour))+
geom_bar(aes(fill = as.numeric(drv$value)))+
ggtitle("Number of comments per hour of the day of a given user")
ggplot(b1, aes(x=hour))+
geom_bar(aes())+
ggtitle("Number of comments per hour of the day of a given user")
View(drv2)
ggplot(b1, aes(x=hour))+
geom_bar(aes(fill = as.numeric(drv3$y)))+
ggtitle("Number of comments per hour of the day of a given user")
View(drv3)
ggplot(b1, aes(x=hour))+
geom_bar(aes(fill = as.numeric(drv3$mean)))+
ggtitle("Number of comments per hour of the day of a given user")
ggplot(b1, aes(x=hour))+
geom_bar(aes())+
geom_line(aes(y=drv3$mean, x=drv3$hour))+
ggtitle("Number of comments per hour of the day of a given user")
ggplot(b1, aes(x=hour))+
geom_bar(aes())+
geom_point(aes(y=drv3$mean, x=drv3$hour))+
ggtitle("Number of comments per hour of the day of a given user")
ggplot(b1, aes(x=hour))+
geom_point(aes(y=drv3$mean, x=drv3$hour))
ggplot(drv3, aes(x=hour))+
geom_point(aes(y=drv3$mean, x=drv3$hour))
ggplot(drv3, aes(x=hour))+
geom_line(aes(y=drv3$mean, x=drv3$hour))
ggplot(drv3, aes(x=hour))+
geom_point(aes(y=drv3$mean, x=drv3$hour))+
geom_line()
ggplot(drv3, aes(x=hour))+
geom_point(aes(y=drv3$mean, x=drv3$hour))+
geom_line()
ggplot(drv3, aes(y=mean, x=dhour))+
geom_point(aes())+
geom_line()
ggplot(drv3, aes(y=mean, x=hour))+
geom_point(aes())+
geom_line()
ggplot(drv3, aes(y=mean, x=hour))+
geom_point(aes())+
ggplot::geom_line()
ggplot(drv3, aes(y=mean, x=hour))+
geom_point(aes())+
ggplot2::geom_line()
ggplot(drv3, aes(y=mean, x=hour, group=1))+
geom_point(aes())+
ggplot2::geom_line()
View(drv)
View(b1)
View(b3)
drv_comment<-b3%>%
dplyr::group_by(ID)%>%
deplyr::inner_join(tidytext::get_sentiments("afinn"), by="word")
drv_comment<-b3%>%
dplyr::group_by(ID)%>%
dplyr::inner_join(tidytext::get_sentiments("afinn"), by="word")
View(drv_comment)
drv_comment_nrc<-b3%>%
dplyr::group_by(ID)%>%
dplyr::inner_join(tidytext::get_sentiments("nrc"), by="word")
View(drv_comment_nrc)
ggplot(drv_comment_nrc, aes(x=hour, fill=sentiments))%>%
geom_bar()
ggplot(drv_comment_nrc, aes(x=hour, fill=sentiments))+
geom_bar()
ggplot(drv_comment_nrc, aes(x=hour, fill=sentiments))+
geom_bar(aes(y=count(ID)))
ggplot(drv_comment_nrc, aes(x=hour))+
geom_bar(aes())
ggplot(drv_comment_nrc, aes(x=hour), fill=sentiments)+
geom_bar(aes())
ggplot(drv_comment_nrc, aes(x=hour), colour=sentiments)+
geom_bar(aes())
ggplot(drv_comment_nrc, aes(x=hour), colours=sentiments)+
geom_bar(aes())
ggplot(drv_comment_nrc, aes(x=hour ,fill=sentiments))+
geom_bar(stat="identity")
ggplot(drv_comment_nrc, aes(x=hour ,fill=sentiment))+
geom_bar(stat="identity")
ggplot(drv_comment_nrc, aes(x=hour ,fill=sentiment))+
geom_bar(stat="identity")
ggplot(drv_comment_nrc, aes(x=hour ,fill=sentiment))+
geom_bar(stat="identity")
ggplot(drv_comment_nrc, aes(x=hour,y=count(word) ,fill=sentiment))+
geom_bar(stat="identity")
ggplot(drv_comment_nrc, aes(x=hour, fill=sentiment,y=y))+
geom_bar(stat="identity")
ggplot(b1, aes(x=hour))+
geom_bar(aes(fill = as.numeric(drv3$mean)))+
ggtitle("Number of comments per hour of the day of a given user")
ggplot(b1, aes(x=hour))+
geom_bar(aes())+
geom_point(aes(y=drv3$mean, x=drv3$hour))+
ggtitle("Number of comments per hour of the day of a given user")
ggplot(drv3, aes(y=mean, x=hour, group=1))+
geom_point(aes())+
ggplot2::geom_line()
ggplot(b1, aes(x=hour))+
geom_bar(aes())+
ggtitle("Number of comments per hour of the day of a given user")
ggplot(drv_comment_nrc, aes(x=hour, fill=sentiment))+
geom_bar(stat="identity")
ggplot(drv_comment_nrc, aes(x=hour)+#, fill=sentiment))+
ggplot(drv_comment_nrc, aes(x=hour))+#, fill=sentiment))+
geom_bar(stat="identity")
ggplot(drv_comment_nrc, aes(x=hour))+#, fill=sentiment))+
geom_bar(stat="identity")
drv_comment_nrc$sentiment<-drv_comment_nrc$sentiment%>%as.factor()
ggplot(drv_comment_nrc, aes(x=hour), fill=sentiment))+
geom_bar(stat="identity")
ggplot(drv_comment_nrc, aes(x=hour), fill=sentiment))+
geom_bar()
ggplot(drv_comment_nrc, aes(x=hour), fill=sentiment)+
geom_bar(aes())
ggplot(drv_comment_nrc, aes(x=hour), color=sentiment)+
geom_bar(aes())
ggplot(drv_comment_nrc, aes(x=hour), colors=sentiment)+
geom_bar(aes())
ggplot(drv_comment_nrc, aes(x=hour), colour=sentiment)+
geom_bar(aes())
ggplot(drv_comment_nrc, aes(x=hour), colours=sentiment)+
geom_bar(aes())
ggplot(drv_comment_nrc, aes(x=hour))+
geom_bar(aes(), colours=sentiment)
ggplot(drv_comment_nrc, aes(x=hour))+
geom_bar(aes( colours=sentiment))
ggplot(drv_comment_nrc, aes(x=hour, colours=sentiment))+
geom_bar(aes())
ggplot(drv_comment_nrc, aes(x=hour, color=sentiment))+
geom_bar(aes())
ggplot(drv_comment_nrc, aes(x=hour, color=sentiment, fill=sentiment))+
geom_bar(aes())
ggplot(drv_comment_nrc, aes(x=hour, color=sentiment))+
geom_bar(aes(color="sentiment"))
ggplot(drv_comment_nrc, aes(x=hour, fill=sentiment))+
geom_bar(aes())
ggplot(drv_comment_nrc, aes(x=hour, fill=sentiment))+
geom_bar(aes())+
theme_minimal()
ggplot(drv_comment, aes(x=hour, fill=value))+
geom_bar(aes())+
theme_minimal()+
ggtitle("Sentiments per hour")
drv_comment2<-drv_comment%>%
mutate(sentiment=ifelse(value<0, "negative", "positive"))
ggplot(drv_comment2, aes(x=hour, fill=sentiment))+
geom_bar(aes())+
theme_minimal()+
ggtitle("Sentiments per hour")
sentiments_per_hour(b)
sentiments_per_hour<-function(b){
#import database of type reddit_content()
b1 <- b
#formatting
b1$date<-ymd_hm(b1$date)
b1<-b %>% dplyr::mutate(year = lubridate::year(date),
month = lubridate::month(date),
day = lubridate::day(date),
hour = lubridate::hour(date),
minute =lubridate :: minute(date))
b1$hour <-as.factor(b1$hour)
b1$ID <- seq.int(nrow(b1))
#Unnest tokens for sentiment analysis
b3<-b1%>%
tibble::as_tibble() %>%
tidytext::unnest_tokens(word, comment) %>%
dplyr::filter(is.na(as.numeric(word)))
#Sentiment analysis
drv_comment<-b3%>%
dplyr::group_by(ID)%>%
dplyr::inner_join(tidytext::get_sentiments("afinn"), by="word")
#Make them either positive or negative for a more easy visualisation
drv_comment2<-drv_comment%>%
mutate(sentiment=ifelse(value<0, "negative", "positive"))
#plot
ggplot(drv_comment2, aes(x=hour, fill=sentiment))+
geom_bar(aes())+
theme_minimal()+
ggtitle("Sentiments per hour")
}
sentiments_per_hour(b)
sentiments_per_hour<-function(b){
#import database of type reddit_content()
b1 <- b
#formatting
b1$date<-lubridate::ymd_hm(b1$date)
b1<-b %>% dplyr::mutate(year = lubridate::year(date),
month = lubridate::month(date),
day = lubridate::day(date),
hour = lubridate::hour(date),
minute =lubridate :: minute(date))
b1$hour <-as.factor(b1$hour)
b1$ID <- seq.int(nrow(b1))
#Unnest tokens for sentiment analysis
b3<-b1%>%
tibble::as_tibble() %>%
tidytext::unnest_tokens(word, comment) %>%
dplyr::filter(is.na(as.numeric(word)))
#Sentiment analysis
drv_comment<-b3%>%
dplyr::group_by(ID)%>%
dplyr::inner_join(tidytext::get_sentiments("afinn"), by="word")
#Make them either positive or negative for a more easy visualisation
drv_comment2<-drv_comment%>%
mutate(sentiment=ifelse(value<0, "negative", "positive"))
#plot
ggplot(drv_comment2, aes(x=hour, fill=sentiment))+
geom_bar(aes())+
theme_minimal()+
ggtitle("Sentiments per hour")
}
sentiments_per_hour(b)
setwd("~/Documents/GitHub/projectg1ptds/R")
devtools::document()
install.packages("leaflet")
install.packages("spdata")
install.packages("spData")
install.packages("tmap")
devtools::document()
